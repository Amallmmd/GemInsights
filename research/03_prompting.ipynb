{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/izam/coding/hackathon'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PromptingConfig:\n",
    "    root_dir: Path\n",
    "    prompt: list\n",
    "    model_name: str\n",
    "    response_file_name: str\n",
    "    candidates_file_name: str\n",
    "    credentials: Path\n",
    "    generation_config: dict\n",
    "    project_name: str\n",
    "    project_location: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gemInsights.constants import *\n",
    "from gemInsights.utils.common import read_yaml, create_directories, load_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#udpate configuration manager\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        credentials_file_path = CREDENTIALS_FILE_PATH,\n",
    "        params_file_path = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.credentials = credentials_file_path\n",
    "        self.params = read_yaml(params_file_path)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_promting_config(self, prompt) -> PromptingConfig:\n",
    "        config = self.config.prompting\n",
    "        \n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        prompting_config = PromptingConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            prompt=prompt,\n",
    "            model_name=config.model_name, \n",
    "            response_file_name=config.response_file_name,\n",
    "            candidates_file_name=config.candidates_file_name,\n",
    "            credentials=self.credentials,\n",
    "            generation_config=dict(self.params.generation_config),\n",
    "            project_name=config.project_name,\n",
    "            project_location=config.project_location            \n",
    "        )\n",
    "\n",
    "        return prompting_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from gemInsights import logger\n",
    "import os\n",
    "import base64\n",
    "import vertexai\n",
    "from vertexai.preview.generative_models import GenerativeModel, Part\n",
    "from gemInsights.utils.common import load_json, save_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prompting:\n",
    "    def __init__(self, config: PromptingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def get_response(self):\n",
    "        aiplatform.init(\n",
    "            project = self.config.project_name,\n",
    "            location= self.config.project_location,\n",
    "        )\n",
    "        logger.info(f\"Google cloud project name - {self.config.project_name}\")\n",
    "        \n",
    "        os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = self.config.credentials\n",
    "        logger.info(\"loaded the google cloud credentials\")\n",
    "\n",
    "        model = GenerativeModel(self.config.model_name)\n",
    "        logger.info(f\"using the model - {self.config.model_name}\")\n",
    "\n",
    "        logger.info(f\"generating response with config - {self.config.generation_config}\")\n",
    "        responses = model.generate_content(\n",
    "            self.config.prompt,\n",
    "            generation_config=self.config.generation_config,\n",
    "            )\n",
    "        \n",
    "        save_json(path=os.path.join(self.config.root_dir, self.config.response_file_name), data={\"response\": responses.text})\n",
    "        logger.info(responses.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "img = open(\"./research/Rating/Dist_Plots_Cats.jpg\", \"rb\").read()\n",
    "img_bytes = Part.from_data(base64.b64decode(base64.encodebytes(img)), mime_type=\"image/jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-21 11:41:16,654: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2023-12-21 11:41:16,656: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-12-21 11:41:16,657: INFO: common: created directory at: artifacts]\n",
      "[2023-12-21 11:41:16,657: INFO: common: created directory at: artifacts/prompting]\n",
      "[2023-12-21 11:41:16,658: INFO: 2160553634: Google cloud project name - ultra-heading-407815]\n",
      "[2023-12-21 11:41:16,658: INFO: 2160553634: loaded the google cloud credentials]\n",
      "[2023-12-21 11:41:16,658: INFO: 2160553634: using the model - gemini-pro-vision]\n",
      "[2023-12-21 11:41:16,659: INFO: 2160553634: generating response with config - {'max_output_tokens': 2048, 'temperature': 0.4, 'top_p': 1, 'top_k': 32}]\n",
      "[2023-12-21 11:41:27,856: INFO: common: json file saved at: artifacts/prompting/response.json]\n",
      "[2023-12-21 11:41:27,856: INFO: 2160553634:  The image shows the distribution of customers, gender, branch, city, product line, payment, and date.\n",
      "\n",
      "The distribution of customers is relatively even between normal and member customers. The distribution of gender is skewed towards males. The distribution of branches is relatively even between the three branches. The distribution of cities is skewed towards Mandalay. The distribution of product lines is relatively even between the top 15 product lines. The distribution of payments is skewed towards cash payments. The distribution of dates is skewed towards the end of the year.]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prompting_config = config.get_promting_config([\"explain this image\", img_bytes])\n",
    "    prompting_config = Prompting(config=prompting_config)\n",
    "    prompting_config.get_response()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hola",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
