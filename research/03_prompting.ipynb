{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/izam/coding/hackathon'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PromptingConfig:\n",
    "    root_dir: Path\n",
    "    model_name: str\n",
    "    response_file_name: str\n",
    "    candidates_file_name: str\n",
    "    credentials: Path\n",
    "    generation_config: dict\n",
    "    project_name: str\n",
    "    project_location: str\n",
    "    prompt_file_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gemInsights.constants import *\n",
    "from gemInsights.utils.common import read_yaml, create_directories, load_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#udpate configuration manager\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        credentials_file_path = CREDENTIALS_FILE_PATH,\n",
    "        params_file_path = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.credentials = credentials_file_path\n",
    "        self.params = read_yaml(params_file_path)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_promting_config(self) -> PromptingConfig:\n",
    "        config = self.config.prompting\n",
    "        \n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        prompting_config = PromptingConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            model_name=config.model_name, \n",
    "            response_file_name=config.response_file_name,\n",
    "            candidates_file_name=config.candidates_file_name,\n",
    "            credentials=self.credentials,\n",
    "            generation_config=dict(self.params.generation_config),\n",
    "            project_name=config.project_name,\n",
    "            project_location=config.project_location,\n",
    "            prompt_file_path=config.prompt_file_path,          \n",
    "        )\n",
    "\n",
    "        return prompting_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from gemInsights import logger\n",
    "import os\n",
    "import base64\n",
    "import vertexai\n",
    "from vertexai.preview.generative_models import GenerativeModel, Part\n",
    "from gemInsights.utils.common import load_json, save_json, load_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prompting:\n",
    "    def __init__(self, config: PromptingConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def get_response(self):\n",
    "        aiplatform.init(\n",
    "            project = self.config.project_name,\n",
    "            location= self.config.project_location,\n",
    "        )\n",
    "        logger.info(f\"Google cloud project name - {self.config.project_name}\")\n",
    "        \n",
    "        os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = self.config.credentials\n",
    "        logger.info(\"loaded the google cloud credentials\")\n",
    "\n",
    "        model = GenerativeModel(self.config.model_name)\n",
    "        logger.info(f\"using the model - {self.config.model_name}\")\n",
    "\n",
    "        logger.info(f\"generating response with config - {self.config.generation_config}\")\n",
    "        prompt = load_bin(Path(self.config.prompt_file_path))\n",
    "        responses = model.generate_content(\n",
    "            prompt,\n",
    "            generation_config=self.config.generation_config,\n",
    "            )\n",
    "        \n",
    "        save_json(path=os.path.join(self.config.root_dir, self.config.response_file_name), data={\"response\": responses.text})\n",
    "        logger.info(responses.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "img = open(\"./research/Rating/Dist_Plots_Cats.jpg\", \"rb\").read()\n",
    "img_bytes = Part.from_data(base64.b64decode(base64.encodebytes(img)), mime_type=\"image/jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-21 12:15:20,445: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2023-12-21 12:15:20,447: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-12-21 12:15:20,448: INFO: common: created directory at: artifacts]\n",
      "[2023-12-21 12:15:20,448: INFO: common: created directory at: artifacts/prompting]\n",
      "[2023-12-21 12:15:20,448: INFO: 3427468588: Google cloud project name - ultra-heading-407815]\n",
      "[2023-12-21 12:15:20,449: INFO: 3427468588: loaded the google cloud credentials]\n",
      "[2023-12-21 12:15:20,449: INFO: 3427468588: using the model - gemini-pro-vision]\n",
      "[2023-12-21 12:15:20,449: INFO: 3427468588: generating response with config - {'max_output_tokens': 2048, 'temperature': 0.4, 'top_p': 1, 'top_k': 32}]\n",
      "[2023-12-21 12:15:20,454: INFO: common: binary file loaded from: artifacts/prompt_generation/prompt.joblib]\n",
      "[2023-12-21 12:15:32,981: INFO: common: json file saved at: artifacts/prompting/response.json]\n",
      "[2023-12-21 12:15:32,982: INFO: 3427468588:  1. The dataset contains information on customer purchases. \n",
      "2. The customers are members and non-members.\n",
      "3. The most popular product category is fashion.\n",
      "4. The least popular product category is health and beauty.\n",
      "5. The average rating for a product is 7.8.\n",
      "6. The most expensive product is in the home and lifestyle category.\n",
      "7. The least expensive product is in the food and beverage category.\n",
      "8. Customers tend to spend more money on products in the fashion category.\n",
      "9. Customers tend to spend less money on products in the health and beauty category.\n",
      "10. There is a positive correlation between the unit price and the rating.\n",
      "11. There is a positive correlation between the quantity and the rating.\n",
      "12. There is a positive correlation between the total and the rating.\n",
      "13. There is a positive correlation between the cogs and the rating.\n",
      "14. There is a positive correlation between the gross income and the rating.\n",
      "15. There is a negative correlation between the tax and the rating.\n",
      "16. The most influential variable on the rating is the unit price.\n",
      "17. The second most influential variable on the rating is the quantity.\n",
      "18. The third most influential variable on the rating is the total.\n",
      "19. The fourth most influential variable on the rating is the cogs.\n",
      "20. The fifth most influential variable on the rating is the gross income.\n",
      "21. The sixth most influential variable on the rating is the tax.]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prompting_config = config.get_promting_config()\n",
    "    prompting_config = Prompting(config=prompting_config)\n",
    "    prompting_config.get_response()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hola",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
