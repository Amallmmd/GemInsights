{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: litellm in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (1.15.3)\n",
      "Requirement already satisfied: aiohttp in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from litellm) (3.9.1)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.4 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from litellm) (1.4.4)\n",
      "Requirement already satisfied: certifi<2024.0.0,>=2023.7.22 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from litellm) (2023.11.17)\n",
      "Requirement already satisfied: click in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from litellm) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from litellm) (6.11.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from litellm) (3.1.2)\n",
      "Requirement already satisfied: openai>=1.0.0 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from litellm) (1.6.0)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from litellm) (1.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.4.0 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from litellm) (0.5.2)\n",
      "Requirement already satisfied: tokenizers in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from litellm) (0.15.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from importlib-metadata>=6.8.0->litellm) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from jinja2<4.0.0,>=3.1.2->litellm) (2.1.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from openai>=1.0.0->litellm) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from openai>=1.0.0->litellm) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from openai>=1.0.0->litellm) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from openai>=1.0.0->litellm) (2.5.2)\n",
      "Requirement already satisfied: sniffio in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from openai>=1.0.0->litellm) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from openai>=1.0.0->litellm) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from openai>=1.0.0->litellm) (4.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from tiktoken>=0.4.0->litellm) (2023.10.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from tiktoken>=0.4.0->litellm) (2.31.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from aiohttp->litellm) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from aiohttp->litellm) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from aiohttp->litellm) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from aiohttp->litellm) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from aiohttp->litellm) (1.3.1)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from tokenizers->litellm) (0.20.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai>=1.0.0->litellm) (3.6)\n",
      "Requirement already satisfied: httpcore==1.* in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->litellm) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0.0->litellm) (0.14.0)\n",
      "Requirement already satisfied: filelock in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers->litellm) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers->litellm) (2023.12.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers->litellm) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers->litellm) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai>=1.0.0->litellm) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai>=1.0.0->litellm) (2.14.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken>=0.4.0->litellm) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/izam/miniconda3/envs/hackathon/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken>=0.4.0->litellm) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install litellm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of `Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import JSON\n",
    "\n",
    "# Imports main tools:\n",
    "from trulens_eval import Feedback, Tru, LiteLLM, Huggingface, TruBasicApp\n",
    "tru = Tru()\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from vertexai.preview.generative_models import GenerativeModel, Part\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(\n",
    "            project = \"ultra-heading-407815\",\n",
    "            location= \"us-central1\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = 'cloud_credentials.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GenerativeModel(\"gemini-pro-vision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens_eval.feedback import Groundedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider = LiteLLM(model_engine='chat-bison-32k', max_output_tokens=2048, temperature=0.0)\n",
    "grounded = Groundedness(groundedness_provider=provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In Criminality, input text will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Insensitivity, input text will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Maliciousness, input text will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Harmfulness, input text will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Coherence, input text will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Coherence, input text will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Currectness, input text will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Helpfulness, input text will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Conciseness, input text will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "# LLM-based feedback functions\n",
    "f_criminality = Feedback(\n",
    "    provider.criminality_with_cot_reasons,\n",
    "    name=\"Criminality\",\n",
    "    higher_is_better=False,\n",
    ").on_output()\n",
    "\n",
    "f_insensitivity = Feedback(\n",
    "    provider.insensitivity_with_cot_reasons,\n",
    "    name=\"Insensitivity\",\n",
    "    higher_is_better=False,\n",
    ").on_output()\n",
    "\n",
    "f_maliciousness = Feedback(\n",
    "    provider.maliciousness_with_cot_reasons,\n",
    "    name=\"Maliciousness\",\n",
    "    higher_is_better=False,\n",
    ").on_output()\n",
    "\n",
    "# Moderation feedback functions\n",
    "f_hate = Feedback(\n",
    "    provider.harmfulness_with_cot_reasons,\n",
    "    name=\"Harmfulness\",\n",
    "    higher_is_better=False\n",
    ").on_output()\n",
    "\n",
    "f_controvertial = Feedback(\n",
    "    provider.controversiality_with_cot_reasons,\n",
    "    name=\"Coherence\",\n",
    "    higher_is_better=False,\n",
    ").on_output()\n",
    "\n",
    "harmless_feedbacks = [\n",
    "    f_criminality,\n",
    "    f_insensitivity,\n",
    "    f_maliciousness,\n",
    "    f_hate,\n",
    "    f_controvertial,\n",
    "]\n",
    "\n",
    "f_coherence = Feedback(\n",
    "    provider.coherence_with_cot_reasons,\n",
    "    name=\"Coherence\",\n",
    "    higher_is_better=True,\n",
    ").on_output()\n",
    "\n",
    "\n",
    "f_currectness = Feedback(\n",
    "    provider.correctness_with_cot_reasons,\n",
    "    name=\"Currectness\",\n",
    "    higher_is_better=True,\n",
    ").on_output()\n",
    "\n",
    "f_helpful = Feedback(\n",
    "    provider.helpfulness_with_cot_reasons,\n",
    "    name=\"Helpfulness\",\n",
    "    higher_is_better=True\n",
    ").on_output()\n",
    "\n",
    "f_conciseness = Feedback(\n",
    "    provider.conciseness_with_cot_reasons,\n",
    "    name=\"Conciseness\",\n",
    "    higher_is_better=True,\n",
    ").on_output()\n",
    "\n",
    "\n",
    "performance_feedback = [\n",
    "    f_coherence,\n",
    "    f_currectness,\n",
    "    f_helpful,\n",
    "    f_conciseness,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feadbacks = harmless_feedbacks+performance_feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "image_path = \"image.jpeg\"\n",
    "img = open(image_path, \"rb\").read()\n",
    "img_bytes = Part.from_data(base64.b64decode(base64.encodebytes(img)), mime_type=\"image/jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This is a photo of a puppy. The breed is an Entlebucher Mountain Dog.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.generate_content([\"explain this image\", img_bytes])\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"explain this image\"\n",
    "\n",
    "def llm_standalone(prompt):\n",
    "    return model.generate_content([\n",
    "        prompt\n",
    "    ]+ [img_bytes, img_bytes]).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The two images are the same.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_standalone(\"explain this 2 images, tell me whether it is same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_app_recorder = TruBasicApp(llm_standalone, app_id=\"Sentiment bot\", feedbacks=all_feadbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new object of type <class 'trulens_eval.tru_basic_app.TruWrapperApp'> at 0x7f118c611590 is calling an instrumented method <function TruWrapperApp._call at 0x7f11b1266840>. The path of this call may be incorrect.\n",
      "Guessing path of new object is app based on other object (0x7f11ac4628d0) using this function.\n"
     ]
    }
   ],
   "source": [
    "with tru_app_recorder as records:\n",
    "    tru_app_recorder.app(\"Explain the image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n",
      "Dashboard already running at path:   URL: http://localhost:8501\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru.stop_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
